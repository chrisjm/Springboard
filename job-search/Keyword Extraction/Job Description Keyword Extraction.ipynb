{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Description Keyword Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: You will need to download the spacy model. See https://spacy.io/usage/models\n",
    "\n",
    "Example: `python -m spacy download en_core_web_sm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pytextrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_ranked_phrases(filename, limit_phrases=20):\n",
    "    '''\n",
    "    Examine the top-ranked phrases in the document\n",
    "    '''\n",
    "    with open(f\"{filename}\", encoding='utf-8') as f:\n",
    "        text = ''.join(f.readlines())\n",
    "    \n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "    tr = pytextrank.TextRank()\n",
    "    nlp.add_pipe(tr.PipelineComponent, name='textrank', last=True)\n",
    "\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    num_phrases = 0\n",
    "    for p in doc._.phrases:\n",
    "        print('{:.4f} {:5d}  {}'.format(p.rank, p.count, p.text))\n",
    "        # print(p.chunks)\n",
    "        num_phrases += 1\n",
    "        \n",
    "        if num_phrases == limit_phrases:\n",
    "            break\n",
    "        \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from operator import itemgetter\n",
    "\n",
    "def summarize(doc, limit_sentences=4):\n",
    "    \n",
    "    sent_bounds = [ [s.start, s.end, set([])] for s in doc.sents ]\n",
    "    limit_phrases = 4\n",
    "    phrase_id = 0\n",
    "    unit_vector = []\n",
    "\n",
    "    for p in doc._.phrases:\n",
    "        # print(phrase_id, p.text, p.rank)\n",
    "\n",
    "        unit_vector.append(p.rank)\n",
    "\n",
    "        for chunk in p.chunks:\n",
    "            # print(\" \", chunk.start, chunk.end)\n",
    "\n",
    "            for sent_start, sent_end, sent_vector in sent_bounds:\n",
    "                if chunk.start >= sent_start and chunk.start <= sent_end:\n",
    "                    # print(\" \", sent_start, chunk.start, chunk.end, sent_end)\n",
    "                    sent_vector.add(phrase_id)\n",
    "                    break\n",
    "\n",
    "        phrase_id += 1\n",
    "\n",
    "        if phrase_id == limit_phrases:\n",
    "            break\n",
    "    \n",
    "    sum_ranks = sum(unit_vector)\n",
    "    unit_vector = [ rank/sum_ranks for rank in unit_vector ]\n",
    "    \n",
    "    sent_rank = {}\n",
    "    sent_id = 0\n",
    "\n",
    "    for sent_start, sent_end, sent_vector in sent_bounds:\n",
    "        # print(sent_vector)\n",
    "        sum_sq = 0.0\n",
    "\n",
    "        for phrase_id in range(len(unit_vector)):\n",
    "            # print(phrase_id, unit_vector[phrase_id])\n",
    "\n",
    "            if phrase_id not in sent_vector:\n",
    "                sum_sq += unit_vector[phrase_id]**2.0\n",
    "\n",
    "        sent_rank[sent_id] = sqrt(sum_sq)\n",
    "        sent_id += 1\n",
    "\n",
    "    # print(sent_rank)\n",
    "\n",
    "    sent_text = {}\n",
    "    sent_id = 0\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        sent_text[sent_id] = sent.text\n",
    "        sent_id += 1\n",
    "\n",
    "    num_sent = 0\n",
    "\n",
    "    for sent_id, rank in sorted(sent_rank.items(), key=itemgetter(1)):\n",
    "        print(f\"({sent_id}) {sent_text[sent_id]}\")\n",
    "        num_sent += 1\n",
    "\n",
    "        if num_sent == limit_sentences:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0755     1  modern data tools\n",
      "0.0733     1  key business strategy questions\n",
      "0.0716     1  new data sources\n",
      "0.0709     1  data trends\n",
      "0.0706     3  data\n",
      "0.0683     1  appropriate data\n",
      "0.0681     1  data cleansing\n",
      "0.0661     1  most data storage\n",
      "0.0654     2  key questions\n",
      "0.0650     1  data literacy\n",
      "0.0620     1  good questions\n",
      "0.0597     1  senior data staff\n",
      "0.0593     2  questions\n",
      "0.0587     1  incoming questions\n",
      "0.0561     1  new tools\n",
      "0.0547     1  business owners\n",
      "0.0545     1  various distributed business functions\n",
      "0.0528     1  business metrics\n",
      "0.0526     1  other tools\n",
      "0.0522     1  new opportunities\n",
      "0.0520     1  business models\n",
      "0.0508     1  business leaders\n",
      "0.0496     1  nonprofit organizations\n",
      "0.0484     1  statistical analysis techniques\n",
      "0.0482     1  experiment design\n",
      "0.0478     3  tools\n",
      "0.0464     1  non-technical audiences\n",
      "0.0455     3  experiments\n",
      "0.0441     3  analysis\n",
      "0.0433     1  the team core data skills\n"
     ]
    }
   ],
   "source": [
    "doc = top_ranked_phrases('../data/nonprofit-data-analyst.txt', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32) A solid background in modern data tools and techniques.\n",
      "(17) Proactively surface, highlight, and explore key business strategy questions with channel owners.\n",
      "\n",
      "(21) Work closely with others on the tech team to make new data sources available and ensure that existing ones are delivering on the data access needs of the organization.\n",
      "\n",
      "(28) Always Learning: Keep up-to-date with technology and data trends and experiment with new tools and products to maintain competitive edge.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summarize(doc, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
